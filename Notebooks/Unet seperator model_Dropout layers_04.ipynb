{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, LeakyReLU, UpSampling1D, Concatenate, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.nn import sigmoid\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = \"/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(tensor, target_shape, match_feature_dim=True):\n",
    "    shape = tf.shape(tensor)\n",
    "    diff = shape - target_shape\n",
    "    assert diff[1] >= 0 # Only positive difference allowed\n",
    "    if diff[1] == 0:\n",
    "        return tensor\n",
    "    crop_start = diff // 2\n",
    "    crop_end = diff - crop_start\n",
    "    return tensor[:, crop_start[1]:-crop_end[1], :]\n",
    "\n",
    "def AudioClip(x, training):\n",
    "    if training:\n",
    "        return x\n",
    "    else:\n",
    "        return tf.maximum(tf.minimum(x, 1.0), -1.0)\n",
    "\n",
    "def difference_output(input_mix, featuremap, source_names, num_channels, filter_width, padding, activation, training):\n",
    "    outputs = dict()\n",
    "    sum_source = 0\n",
    "    for name in source_names[:-1]:\n",
    "        out = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "        outputs[name] = out\n",
    "        sum_source += out\n",
    "\n",
    "    last_source = crop(input_mix, sum_source.shape) - sum_source\n",
    "    last_source = AudioClip(last_source, training)\n",
    "    outputs[source_names[-1]] = last_source\n",
    "    return outputs\n",
    "def learned_interpolation_layer(input, padding, level):\n",
    "    features = input.shape[2]\n",
    "    weights = tf.Variable(tf.initializers.GlorotUniform()(shape=[features]), dtype=tf.float32, name=\"interp_\" + str(level))\n",
    "    weights_scaled = tf.nn.sigmoid(weights)\n",
    "    counter_weights = 1.0 - weights_scaled\n",
    "\n",
    "    conv_weights = tf.linalg.diag(weights_scaled)\n",
    "    conv_weights = tf.expand_dims(conv_weights, axis=0)\n",
    "    intermediate_vals = tf.linalg.matmul(input, conv_weights)\n",
    "    \n",
    "    counter_conv_weights = tf.linalg.diag(counter_weights)\n",
    "    counter_conv_weights = tf.expand_dims(counter_conv_weights, axis=0)\n",
    "    counter_intermediate_vals = tf.linalg.matmul(input, counter_conv_weights)\n",
    "\n",
    "    output = tf.concat([intermediate_vals, counter_intermediate_vals], axis=1)\n",
    "    \n",
    "    if padding == \"valid\":\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_encoder(input, num_layers, num_initial_filters, filter_size, input_filter_size, padding, dropout_rate=0.3):\n",
    "    enc_outputs = []\n",
    "    current_layer = input\n",
    "    current_layer = tf.keras.layers.Conv1D(num_initial_filters, input_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "    current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "    enc_outputs.append(current_layer)\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters + (num_initial_filters * i), filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "        current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "        current_layer = current_layer[:, ::2, :]  # Decimate by factor of 2\n",
    "        enc_outputs.append(current_layer)\n",
    "\n",
    "    return enc_outputs\n",
    "\n",
    "def create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling):\n",
    "    current_layer = enc_outputs[-1]\n",
    "\n",
    "    for i in range(num_layers - 1, 0, -1):\n",
    "        if upsampling == 'linear':\n",
    "            current_layer = tf.keras.layers.UpSampling1D(size=2)(current_layer)\n",
    "        elif upsampling == 'learned':\n",
    "            current_layer = learned_interpolation_layer(current_layer, padding=padding, level=i)\n",
    "\n",
    "        current_layer = tf.concat([current_layer, enc_outputs[i - 1]], axis=2)\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters * (num_layers - i), merge_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "\n",
    "    return current_layer\n",
    "\n",
    "\n",
    "def get_output_layer(current_layer, output_type, source_names, num_channels, output_filter_size, padding, activation, training):\n",
    "    if output_type == \"direct\":\n",
    "        return independent_outputs(current_layer, source_names, num_channels, output_filter_size, padding, activation)\n",
    "    elif output_type == \"difference\":\n",
    "        cropped_input = crop(input, current_layer.get_shape().as_list(), match_feature_dim=False)\n",
    "        return difference_output(cropped_input, current_layer, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown output type\")\n",
    "\n",
    "def independent_outputs(featuremap, source_names, num_channels, filter_width, padding, activation):\n",
    "    outputs = dict()\n",
    "    for name in source_names:\n",
    "        outputs[name] = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    # Input\n",
    "    input_mix = Input(shape=(num_frames, num_channels), name=\"input\")\n",
    "\n",
    "    # Encoder\n",
    "    enc_outputs = create_encoder(input_mix, num_layers, num_initial_filters, filter_size, input_filter_size, padding)\n",
    "\n",
    "    # Decoder\n",
    "    current_layer = create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = get_output_layer(current_layer, output_type, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "\n",
    "    # Build Model\n",
    "    model = Model(inputs=input_mix, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 11:50:08.002071: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-08-12 11:50:08.002092: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-12 11:50:08.002099: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-12 11:50:08.002160: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-12 11:50:08.002390: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 16384, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 16384, 24)            384       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16384, 24)            0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 16384, 24)            8664      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16384, 24)            0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 8192, 24)             0         ['dropout_1[0][0]']           \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 8192, 48)             17328     ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 8192, 48)             0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 4096, 48)             0         ['dropout_2[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 4096, 72)             51912     ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 4096, 72)             0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 2048, 72)             0         ['dropout_3[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 2048, 96)             103776    ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 2048, 96)             0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 1024, 96)             0         ['dropout_4[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 1024, 120)            172920    ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 1024, 120)            0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 512, 120)             0         ['dropout_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 512, 144)             259344    ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 512, 144)             0         ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 256, 144)             0         ['dropout_6[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 256, 168)             363048    ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 256, 168)             0         ['conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 128, 168)             0         ['dropout_7[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 128, 192)             484032    ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128, 192)             0         ['conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 64, 192)              0         ['dropout_8[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 64, 216)              622296    ['tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 64, 216)              0         ['conv1d_9[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8  (None, 32, 216)              0         ['dropout_9[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 32, 240)              777840    ['tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 32, 240)              0         ['conv1d_10[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9  (None, 16, 240)              0         ['dropout_10[0][0]']          \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 16, 264)              950664    ['tf.__operators__.getitem_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 16, 264)              0         ['conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 8, 264)               0         ['dropout_11[0][0]']          \n",
      " 0 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling1d (UpSampling1  (None, 16, 264)              0         ['tf.__operators__.getitem_10[\n",
      " D)                                                                 0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 16, 504)              0         ['up_sampling1d[0][0]',       \n",
      "                                                                     'tf.__operators__.getitem_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 16, 24)               60504     ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling1d_1 (UpSamplin  (None, 32, 24)               0         ['conv1d_12[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 32, 240)              0         ['up_sampling1d_1[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 32, 48)               57648     ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_2 (UpSamplin  (None, 64, 48)               0         ['conv1d_13[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 64, 240)              0         ['up_sampling1d_2[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 64, 72)               86472     ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_3 (UpSamplin  (None, 128, 72)              0         ['conv1d_14[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 128, 240)             0         ['up_sampling1d_3[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 128, 96)              115296    ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_4 (UpSamplin  (None, 256, 96)              0         ['conv1d_15[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 256, 240)             0         ['up_sampling1d_4[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 256, 120)             144120    ['tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_5 (UpSamplin  (None, 512, 120)             0         ['conv1d_16[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, 512, 240)             0         ['up_sampling1d_5[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 512, 144)             172944    ['tf.concat_5[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_6 (UpSamplin  (None, 1024, 144)            0         ['conv1d_17[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, 1024, 240)            0         ['up_sampling1d_6[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 1024, 168)            201768    ['tf.concat_6[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_7 (UpSamplin  (None, 2048, 168)            0         ['conv1d_18[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, 2048, 240)            0         ['up_sampling1d_7[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 2048, 192)            230592    ['tf.concat_7[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_8 (UpSamplin  (None, 4096, 192)            0         ['conv1d_19[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)    (None, 4096, 240)            0         ['up_sampling1d_8[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 4096, 216)            259416    ['tf.concat_8[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_9 (UpSamplin  (None, 8192, 216)            0         ['conv1d_20[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)    (None, 8192, 240)            0         ['up_sampling1d_9[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 8192, 240)            288240    ['tf.concat_9[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_10 (UpSampli  (None, 16384, 240)           0         ['conv1d_21[0][0]']           \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)   (None, 16384, 264)           0         ['up_sampling1d_10[0][0]',    \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 16384, 264)           348744    ['tf.concat_10[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 16384, 1)             265       ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 16384, 1)             265       ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5778482 (22.04 MB)\n",
      "Trainable params: 5778482 (22.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_frames = 16384 #* 2\n",
    "num_channels = 1\n",
    "num_layers = 12 #12\n",
    "num_initial_filters = 24 #24\n",
    "filter_size = 15 #15\n",
    "merge_filter_size = 5\n",
    "input_filter_size = 15\n",
    "output_filter_size = 1\n",
    "padding = 'same'  \n",
    "upsampling = 'linear'  # or 'learned'\n",
    "output_type = 'direct'  # or 'difference'\n",
    "source_names = [\"accompaniment\", \"vocals\"]\n",
    "activation = 'tanh'\n",
    "training = True\n",
    "\n",
    "learning_rate = 0.004\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "\n",
    "# Building the model\n",
    "model = build_model()\n",
    "\n",
    "# Compile the model (if needed)\n",
    "model.compile(optimizer='adam', loss='mse') # or other appropriate loss and optimizer\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "SNIPPET_LENGTH = num_frames\n",
    "tfRecord_Datasets = '/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/tf_Record'\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'mixed_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32),\n",
    "        'vocal_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return example['mixed_signal'], example['vocal_signal']\n",
    "\n",
    "def load_dataset(filename):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    return raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Load your training, validation and test data\n",
    "train_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'long_train.tfrecord'))\n",
    "val_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'long_val.tfrecord'))\n",
    "test_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'long_test.tfrecord'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "callbacks = [reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /Users/rei/anaconda3/envs/TflowGPU/lib/python3.11/site-packages/wandb/sdk/wandb_init.py 829 getcaller\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwandb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m WandbCallback\n\u001b[0;32m----> 4\u001b[0m wandb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mShaking_Through_Unet_model_lr_GPU\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TflowGPU/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[39mif\u001b[39;00m logger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         logger\u001b[39m.\u001b[39mexception(\u001b[39mstr\u001b[39m(e))\n\u001b[0;32m-> 1166\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1167\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1168\u001b[0m     \u001b[39massert\u001b[39;00m logger\n",
      "File \u001b[0;32m~/anaconda3/envs/TflowGPU/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1147\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1145\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1146\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1148\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1149\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/TflowGPU/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:762\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         backend\u001b[39m.\u001b[39mcleanup()\n\u001b[1;32m    761\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    764\u001b[0m \u001b[39massert\u001b[39;00m run_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m run_result\u001b[39m.\u001b[39mHasField(\u001b[39m\"\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project='Shaking_Through_Unet_model_lr_GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks.append(WandbCallback(log_weights=True))\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "callbacks.extend([checkpoint, early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 11:52:34.898804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 1e-8\n",
    "max_lr = 0.04  # You can adjust this depending on how high you want to test\n",
    "lr_multiplier = (max_lr/initial_lr)**(1/EPOCHS)\n",
    "\n",
    "# Custom Callback for Learning Rate Test\n",
    "class LearningRateRangeTest(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, max_lr):\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_logs = []\n",
    "        self.loss_logs = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Adjust the learning rate of the optimizer\n",
    "        lr = initial_lr * (lr_multiplier ** epoch)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Record the learning rate and loss\n",
    "        lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        self.lr_logs.append(lr)\n",
    "        self.loss_logs.append(logs[\"loss\"])\n",
    "        if lr > self.max_lr:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "lr_test = LearningRateRangeTest(max_lr=max_lr)\n",
    "\n",
    "# Compiling and Training the Model\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=initial_lr), loss='mse')\n",
    "\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE), \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "                    callbacks=[lr_test])  # Only use the LR test callback\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogx(lr_test.lr_logs, lr_test.loss_logs)\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "      9/Unknown - 2593s 102s/step - loss: 1.8845 - conv1d_560_loss: 0.9403 - conv1d_561_loss: 0.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rei/anaconda3/envs/Tflow/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2661s 111s/step - loss: 1.8845 - conv1d_560_loss: 0.9403 - conv1d_561_loss: 0.9442 - val_loss: 2.1746 - val_conv1d_560_loss: 1.0873 - val_conv1d_561_loss: 1.0873 - lr: 0.0040\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rei/anaconda3/envs/Tflow/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - ETA: 0s - loss: 2.1478 - conv1d_560_loss: 1.0739 - conv1d_561_loss: 1.0739  INFO:tensorflow:Assets written to: /Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230811_232609-l0b6az3u/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 998s 111s/step - loss: 2.1478 - conv1d_560_loss: 1.0739 - conv1d_561_loss: 1.0739 - val_loss: 2.1412 - val_conv1d_560_loss: 1.0873 - val_conv1d_561_loss: 1.0539 - lr: 0.0040\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rei/anaconda3/envs/Tflow/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1009s 113s/step - loss: 2.1232 - conv1d_560_loss: 1.0673 - conv1d_561_loss: 1.0558 - val_loss: 2.1746 - val_conv1d_560_loss: 1.0873 - val_conv1d_561_loss: 1.0873 - lr: 0.0040\n",
      "Epoch 4/200\n",
      "6/9 [===================>..........] - ETA: 5:38 - loss: 2.1460 - conv1d_560_loss: 1.0845 - conv1d_561_loss: 1.0614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define batch size and number of epochs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mlegacy\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlearning_rate), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, )\n\u001b[0;32m----> 6\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(train_dataset\u001b[39m.\u001b[39mbatch(BATCH_SIZE), \n\u001b[1;32m      7\u001b[0m           epochs\u001b[39m=\u001b[39mEPOCHS, \n\u001b[1;32m      8\u001b[0m           validation_data\u001b[39m=\u001b[39mval_dataset\u001b[39m.\u001b[39mbatch(BATCH_SIZE),\n\u001b[1;32m      9\u001b[0m           callbacks\u001b[39m=\u001b[39mcallbacks)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function(\u001b[39m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/Tflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define batch size and number of epochs\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='mse', )\n",
    "\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE), \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "          callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "callbacks.extend([checkpoint, early_stopping])\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE), \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "          callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
