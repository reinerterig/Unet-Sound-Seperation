{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, LeakyReLU, UpSampling1D, Concatenate, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.nn import sigmoid\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = \"/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(tensor, target_shape, match_feature_dim=True):\n",
    "    shape = tf.shape(tensor)\n",
    "    diff = shape - target_shape\n",
    "    assert diff[1] >= 0 # Only positive difference allowed\n",
    "    if diff[1] == 0:\n",
    "        return tensor\n",
    "    crop_start = diff // 2\n",
    "    crop_end = diff - crop_start\n",
    "    return tensor[:, crop_start[1]:-crop_end[1], :]\n",
    "\n",
    "def AudioClip(x, training):\n",
    "    if training:\n",
    "        return x\n",
    "    else:\n",
    "        return tf.maximum(tf.minimum(x, 1.0), -1.0)\n",
    "\n",
    "def difference_output(input_mix, featuremap, source_names, num_channels, filter_width, padding, activation, training):\n",
    "    outputs = dict()\n",
    "    sum_source = 0\n",
    "    for name in source_names[:-1]:\n",
    "        out = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "        outputs[name] = out\n",
    "        sum_source += out\n",
    "\n",
    "    last_source = crop(input_mix, sum_source.shape) - sum_source\n",
    "    last_source = AudioClip(last_source, training)\n",
    "    outputs[source_names[-1]] = last_source\n",
    "    return outputs\n",
    "def learned_interpolation_layer(input, padding, level):\n",
    "    features = input.shape[2]\n",
    "    weights = tf.Variable(tf.initializers.GlorotUniform()(shape=[features]), dtype=tf.float32, name=\"interp_\" + str(level))\n",
    "    weights_scaled = tf.nn.sigmoid(weights)\n",
    "    counter_weights = 1.0 - weights_scaled\n",
    "\n",
    "    conv_weights = tf.linalg.diag(weights_scaled)\n",
    "    conv_weights = tf.expand_dims(conv_weights, axis=0)\n",
    "    intermediate_vals = tf.linalg.matmul(input, conv_weights)\n",
    "    \n",
    "    counter_conv_weights = tf.linalg.diag(counter_weights)\n",
    "    counter_conv_weights = tf.expand_dims(counter_conv_weights, axis=0)\n",
    "    counter_intermediate_vals = tf.linalg.matmul(input, counter_conv_weights)\n",
    "\n",
    "    output = tf.concat([intermediate_vals, counter_intermediate_vals], axis=1)\n",
    "    \n",
    "    if padding == \"valid\":\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_encoder(input, num_layers, num_initial_filters, filter_size, input_filter_size, padding, dropout_rate=0.3):\n",
    "    enc_outputs = []\n",
    "    current_layer = input\n",
    "    current_layer = tf.keras.layers.Conv1D(num_initial_filters, input_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "    current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "    enc_outputs.append(current_layer)\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters + (num_initial_filters * i), filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "        current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "        current_layer = current_layer[:, ::2, :]  # Decimate by factor of 2\n",
    "        enc_outputs.append(current_layer)\n",
    "\n",
    "    return enc_outputs\n",
    "\n",
    "def create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling):\n",
    "    current_layer = enc_outputs[-1]\n",
    "\n",
    "    for i in range(num_layers - 1, 0, -1):\n",
    "        if upsampling == 'linear':\n",
    "            current_layer = tf.keras.layers.UpSampling1D(size=2)(current_layer)\n",
    "        elif upsampling == 'learned':\n",
    "            current_layer = learned_interpolation_layer(current_layer, padding=padding, level=i)\n",
    "\n",
    "        current_layer = tf.concat([current_layer, enc_outputs[i - 1]], axis=2)\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters * (num_layers - i), merge_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "\n",
    "    return current_layer\n",
    "\n",
    "\n",
    "def get_output_layer(current_layer, output_type, source_names, num_channels, output_filter_size, padding, activation, training):\n",
    "    if output_type == \"direct\":\n",
    "        return independent_outputs(current_layer, source_names, num_channels, output_filter_size, padding, activation)\n",
    "    elif output_type == \"difference\":\n",
    "        cropped_input = crop(input, current_layer.get_shape().as_list(), match_feature_dim=False)\n",
    "        return difference_output(cropped_input, current_layer, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown output type\")\n",
    "\n",
    "def independent_outputs(featuremap, source_names, num_channels, filter_width, padding, activation):\n",
    "    outputs = dict()\n",
    "    for name in source_names:\n",
    "        outputs[name] = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    # Input\n",
    "    input_mix = Input(shape=(num_frames, num_channels), name=\"input\")\n",
    "\n",
    "    # Encoder\n",
    "    enc_outputs = create_encoder(input_mix, num_layers, num_initial_filters, filter_size, input_filter_size, padding)\n",
    "\n",
    "    # Decoder\n",
    "    current_layer = create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = get_output_layer(current_layer, output_type, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "\n",
    "    # Build Model\n",
    "    model = Model(inputs=input_mix, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.001\n",
    "BATCH_SIZE = 12\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 20:45:57.359302: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-08-12 20:45:57.359320: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-12 20:45:57.359325: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-12 20:45:57.359404: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-12 20:45:57.359655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 16384, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 16384, 24)            384       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16384, 24)            0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 16384, 24)            8664      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16384, 24)            0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 8192, 24)             0         ['dropout_1[0][0]']           \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 8192, 48)             17328     ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 8192, 48)             0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 4096, 48)             0         ['dropout_2[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 4096, 72)             51912     ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 4096, 72)             0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 2048, 72)             0         ['dropout_3[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 2048, 96)             103776    ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 2048, 96)             0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 1024, 96)             0         ['dropout_4[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 1024, 120)            172920    ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 1024, 120)            0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 512, 120)             0         ['dropout_5[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 512, 144)             259344    ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 512, 144)             0         ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 256, 144)             0         ['dropout_6[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 256, 168)             363048    ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 256, 168)             0         ['conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 128, 168)             0         ['dropout_7[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 128, 192)             484032    ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128, 192)             0         ['conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 64, 192)              0         ['dropout_8[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 64, 216)              622296    ['tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 64, 216)              0         ['conv1d_9[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8  (None, 32, 216)              0         ['dropout_9[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 32, 240)              777840    ['tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 32, 240)              0         ['conv1d_10[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9  (None, 16, 240)              0         ['dropout_10[0][0]']          \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 16, 264)              950664    ['tf.__operators__.getitem_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 16, 264)              0         ['conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 8, 264)               0         ['dropout_11[0][0]']          \n",
      " 0 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling1d (UpSampling1  (None, 16, 264)              0         ['tf.__operators__.getitem_10[\n",
      " D)                                                                 0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 16, 504)              0         ['up_sampling1d[0][0]',       \n",
      "                                                                     'tf.__operators__.getitem_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 16, 24)               60504     ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling1d_1 (UpSamplin  (None, 32, 24)               0         ['conv1d_12[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 32, 240)              0         ['up_sampling1d_1[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 32, 48)               57648     ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_2 (UpSamplin  (None, 64, 48)               0         ['conv1d_13[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 64, 240)              0         ['up_sampling1d_2[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 64, 72)               86472     ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_3 (UpSamplin  (None, 128, 72)              0         ['conv1d_14[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 128, 240)             0         ['up_sampling1d_3[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 128, 96)              115296    ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_4 (UpSamplin  (None, 256, 96)              0         ['conv1d_15[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 256, 240)             0         ['up_sampling1d_4[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 256, 120)             144120    ['tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_5 (UpSamplin  (None, 512, 120)             0         ['conv1d_16[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, 512, 240)             0         ['up_sampling1d_5[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 512, 144)             172944    ['tf.concat_5[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_6 (UpSamplin  (None, 1024, 144)            0         ['conv1d_17[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, 1024, 240)            0         ['up_sampling1d_6[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 1024, 168)            201768    ['tf.concat_6[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_7 (UpSamplin  (None, 2048, 168)            0         ['conv1d_18[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, 2048, 240)            0         ['up_sampling1d_7[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 2048, 192)            230592    ['tf.concat_7[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_8 (UpSamplin  (None, 4096, 192)            0         ['conv1d_19[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)    (None, 4096, 240)            0         ['up_sampling1d_8[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 4096, 216)            259416    ['tf.concat_8[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_9 (UpSamplin  (None, 8192, 216)            0         ['conv1d_20[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)    (None, 8192, 240)            0         ['up_sampling1d_9[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 8192, 240)            288240    ['tf.concat_9[0][0]']         \n",
      "                                                                                                  \n",
      " up_sampling1d_10 (UpSampli  (None, 16384, 240)           0         ['conv1d_21[0][0]']           \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)   (None, 16384, 264)           0         ['up_sampling1d_10[0][0]',    \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 16384, 264)           348744    ['tf.concat_10[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 16384, 1)             265       ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 16384, 1)             265       ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5778482 (22.04 MB)\n",
      "Trainable params: 5778482 (22.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_frames = 16384# * 2\n",
    "num_channels = 1\n",
    "num_layers = 12 #12\n",
    "num_initial_filters = 24 #24\n",
    "filter_size = 15 #15\n",
    "merge_filter_size = 5\n",
    "input_filter_size = 15\n",
    "output_filter_size = 1\n",
    "padding = 'same'  \n",
    "upsampling = 'linear'  # or 'learned'\n",
    "output_type = 'direct'  # or 'difference'\n",
    "source_names = [\"accompaniment\", \"vocals\"]\n",
    "activation = 'tanh'\n",
    "training = True\n",
    "\n",
    "\n",
    "\n",
    "# Building the model\n",
    "model = build_model()\n",
    "\n",
    "# Compile the model (if needed)\n",
    "model.compile(optimizer='adam', loss='mse') # or other appropriate loss and optimizer\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "SNIPPET_LENGTH = num_frames\n",
    "tfRecord_Datasets = '/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/tf_Record'\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'mixed_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32),\n",
    "        'vocal_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return example['mixed_signal'], example['vocal_signal']\n",
    "\n",
    "def load_dataset(filename):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    return raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Load your training, validation and test data\n",
    "train_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'train.tfrecord'))\n",
    "val_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'val.tfrecord'))\n",
    "test_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'test.tfrecord'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "callbacks = [reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreinert-wasserman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Notebooks/wandb/run-20230812_204559-nbsjz3fw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU/runs/nbsjz3fw' target=\"_blank\">dashing-armadillo-1</a></strong> to <a href='https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU' target=\"_blank\">https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU/runs/nbsjz3fw' target=\"_blank\">https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU/runs/nbsjz3fw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/reinert-wasserman/Large_Shaking_Through_Unet_model_Lr_Test_GPU/runs/nbsjz3fw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2ec506dd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project='Large_Shaking_Through_Unet_model_Lr_Test_GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 20:46:21.142850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     77/Unknown - 1686s 10s/step - loss: 0.2512 - conv1d_23_loss: 0.1242 - conv1d_24_loss: 0.1269 - conv1d_23_accuracy: 0.0000e+00 - conv1d_24_accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Starting the learning rate very low\n",
    "initial_lr = 1e-5\n",
    "max_lr = 0.04  # You can adjust this depending on how high you want to test\n",
    "lr_multiplier = (max_lr/initial_lr)**(1/EPOCHS)\n",
    "\n",
    "# Custom Callback for Learning Rate Test\n",
    "class LearningRateRangeTest(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, max_lr):\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_logs = []\n",
    "        self.loss_logs = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Adjust the learning rate of the optimizer\n",
    "        lr = initial_lr * (lr_multiplier ** epoch)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Record the learning rate and loss\n",
    "        lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        self.lr_logs.append(lr)\n",
    "        self.loss_logs.append(logs[\"loss\"])\n",
    "        if lr > self.max_lr:\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "\n",
    "lr_test = LearningRateRangeTest(max_lr=max_lr)\n",
    "\n",
    "# Compiling and Training the Model\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=initial_lr), loss='mse',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE), \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "                    callbacks=[lr_test,WandbCallback(log_weights=True, monitor = \"val_loss\")])  # Only use the LR test callback\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogx(lr_test.lr_logs, lr_test.loss_logs)\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncallbacks.append(WandbCallback(log_weights=True))\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\\n\\ncheckpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss')\\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\\n\\ncallbacks.extend([checkpoint, early_stopping])\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "callbacks.append(WandbCallback(log_weights=True))\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "callbacks.extend([checkpoint, early_stopping])\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
