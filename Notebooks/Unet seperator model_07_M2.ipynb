{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, LeakyReLU, UpSampling1D, Concatenate, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.nn import sigmoid\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 16384# * 2\n",
    "num_channels = 1\n",
    "num_layers = 12 #12\n",
    "num_initial_filters = 24 #24\n",
    "filter_size = 15 #15\n",
    "merge_filter_size = 5\n",
    "input_filter_size = 15\n",
    "output_filter_size = 1\n",
    "padding = 'same'  \n",
    "upsampling = 'linear'  # or 'learned'\n",
    "output_type = 'difference'  # or  'direct'\n",
    "source_names = [\"accompaniment\", \"vocals\"]\n",
    "activation = 'tanh'\n",
    "training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate R-squared, the coefficient of determination.\n",
    "    \"\"\"\n",
    "    residual = tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred)))\n",
    "    total = tf.reduce_sum(tf.square(tf.subtract(y_true, tf.reduce_mean(y_true))))\n",
    "    r2 = tf.subtract(1.0, tf.divide(residual, total))\n",
    "    return r2\n",
    "\n",
    "models_folder = \"/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/\"\n",
    "save_path = '/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/best_model.h5'\n",
    "\n",
    "# load M1\n",
    "model_m1 = load_model(save_path, custom_objects={'r_squared': r_squared})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def crop(tensor, target_shape, match_feature_dim=True):\n",
    "    '''\n",
    "    Crops a 3D tensor [batch_size, width, channels] along the width axes to a target shape.\n",
    "    Performs a center crop. If the dimension difference is uneven, crop the last dimensions first.\n",
    "    :param tensor: 3D tensor [batch_size, width, channels] that should be cropped. \n",
    "    :param target_shape: Target shape (3D tensor) that the tensor should be cropped to\n",
    "    :return: Cropped tensor\n",
    "    '''\n",
    "    tensor_shape = tf.shape(tensor)\n",
    "    \n",
    "    diff = tensor_shape - target_shape\n",
    "    \n",
    "    crop_start = diff // 2\n",
    "    cropped_tensor = tensor[:, crop_start[1]:crop_start[1]+target_shape[1], :]\n",
    "    return cropped_tensor\n",
    "\n",
    "\n",
    "\n",
    "def AudioClip(x, training):\n",
    "    if training:\n",
    "        return x\n",
    "    else:\n",
    "        return tf.maximum(tf.minimum(x, 1.0), -1.0)\n",
    "\n",
    "def difference_output(input_mix, featuremap, source_names, num_channels, filter_width, padding, activation, training):\n",
    "    outputs = dict()\n",
    "    sum_source = 0\n",
    "    for name in source_names[:-1]:\n",
    "        out = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "        outputs[name] = out\n",
    "        sum_source += out\n",
    "\n",
    "    last_source = crop(input_mix, tf.shape(sum_source)) - sum_source\n",
    "\n",
    "    last_source = AudioClip(last_source, training)\n",
    "    outputs[source_names[-1]] = last_source\n",
    "    return outputs\n",
    "\n",
    "def learned_interpolation_layer(input, padding, level):\n",
    "    features = input.shape[2]\n",
    "    weights = tf.Variable(tf.initializers.GlorotUniform()(shape=[features]), dtype=tf.float32, name=\"interp_\" + str(level))\n",
    "    weights_scaled = tf.nn.sigmoid(weights)\n",
    "    counter_weights = 1.0 - weights_scaled\n",
    "\n",
    "    conv_weights = tf.linalg.diag(weights_scaled)\n",
    "    conv_weights = tf.expand_dims(conv_weights, axis=0)\n",
    "    intermediate_vals = tf.linalg.matmul(input, conv_weights)\n",
    "    \n",
    "    counter_conv_weights = tf.linalg.diag(counter_weights)\n",
    "    counter_conv_weights = tf.expand_dims(counter_conv_weights, axis=0)\n",
    "    counter_intermediate_vals = tf.linalg.matmul(input, counter_conv_weights)\n",
    "\n",
    "    output = tf.concat([intermediate_vals, counter_intermediate_vals], axis=1)\n",
    "    \n",
    "    if padding == \"valid\":\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_encoder(input, num_layers, num_initial_filters, filter_size, input_filter_size, padding, dropout_rate=0.3):\n",
    "    enc_outputs = []\n",
    "    current_layer = input\n",
    "    current_layer = tf.keras.layers.Conv1D(num_initial_filters, input_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "    current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "    enc_outputs.append(current_layer)\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters + (num_initial_filters * i), filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "        current_layer = tf.keras.layers.Dropout(dropout_rate)(current_layer)  # Adding dropout here\n",
    "        current_layer = current_layer[:, ::2, :]  # Decimate by factor of 2\n",
    "        enc_outputs.append(current_layer)\n",
    "\n",
    "    return enc_outputs\n",
    "\n",
    "def create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling):\n",
    "    current_layer = enc_outputs[-1]\n",
    "\n",
    "    for i in range(num_layers - 1, 0, -1):\n",
    "        if upsampling == 'linear':\n",
    "            current_layer = tf.keras.layers.UpSampling1D(size=2)(current_layer)\n",
    "        elif upsampling == 'learned':\n",
    "            current_layer = learned_interpolation_layer(current_layer, padding=padding, level=i)\n",
    "\n",
    "        current_layer = tf.concat([current_layer, enc_outputs[i - 1]], axis=2)\n",
    "        current_layer = tf.keras.layers.Conv1D(num_initial_filters * (num_layers - i), merge_filter_size, strides=1, activation=LeakyReLU(), padding=padding)(current_layer)\n",
    "\n",
    "    return current_layer\n",
    "\n",
    "\n",
    "def get_output_layer(current_layer, input_mix, output_type, source_names, num_channels, output_filter_size, padding, activation, training):\n",
    "    if output_type == \"direct\":\n",
    "        return independent_outputs(current_layer, source_names, num_channels, output_filter_size, padding, activation)\n",
    "    elif output_type == \"difference\":\n",
    "        cropped_input = crop(input_mix, K.shape(current_layer), match_feature_dim=False)\n",
    "        return difference_output(cropped_input, current_layer, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown output type\")\n",
    "\n",
    "\n",
    "def independent_outputs(featuremap, source_names, num_channels, filter_width, padding, activation):\n",
    "    outputs = dict()\n",
    "    for name in source_names:\n",
    "        outputs[name] = tf.keras.layers.Conv1D(num_channels, filter_width, activation=activation, padding=padding)(featuremap)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 16384, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 16384, 24)            384       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16384, 24)            0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 16384, 24)            8664      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16384, 24)            0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 8192, 24)             0         ['dropout_1[0][0]']           \n",
      " 1 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 8192, 48)             17328     ['tf.__operators__.getitem_11[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 8192, 48)             0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 4096, 48)             0         ['dropout_2[0][0]']           \n",
      " 2 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 4096, 72)             51912     ['tf.__operators__.getitem_12[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 4096, 72)             0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 2048, 72)             0         ['dropout_3[0][0]']           \n",
      " 3 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 2048, 96)             103776    ['tf.__operators__.getitem_13[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 2048, 96)             0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1024, 96)             0         ['dropout_4[0][0]']           \n",
      " 4 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 1024, 120)            172920    ['tf.__operators__.getitem_14[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 1024, 120)            0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 512, 120)             0         ['dropout_5[0][0]']           \n",
      " 5 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 512, 144)             259344    ['tf.__operators__.getitem_15[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 512, 144)             0         ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 256, 144)             0         ['dropout_6[0][0]']           \n",
      " 6 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 256, 168)             363048    ['tf.__operators__.getitem_16[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 256, 168)             0         ['conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 128, 168)             0         ['dropout_7[0][0]']           \n",
      " 7 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 128, 192)             484032    ['tf.__operators__.getitem_17[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128, 192)             0         ['conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 64, 192)              0         ['dropout_8[0][0]']           \n",
      " 8 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 64, 216)              622296    ['tf.__operators__.getitem_18[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 64, 216)              0         ['conv1d_9[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 32, 216)              0         ['dropout_9[0][0]']           \n",
      " 9 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 32, 240)              777840    ['tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 32, 240)              0         ['conv1d_10[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 16, 240)              0         ['dropout_10[0][0]']          \n",
      " 0 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 16, 264)              950664    ['tf.__operators__.getitem_20[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 16, 264)              0         ['conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 8, 264)               0         ['dropout_11[0][0]']          \n",
      " 1 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " up_sampling1d (UpSampling1  (None, 16, 264)              0         ['tf.__operators__.getitem_21[\n",
      " D)                                                                 0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat_11 (TFOpLambda)   (None, 16, 504)              0         ['up_sampling1d[0][0]',       \n",
      "                                                                     'tf.__operators__.getitem_20[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 16, 24)               60504     ['tf.concat_11[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_1 (UpSamplin  (None, 32, 24)               0         ['conv1d_12[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_12 (TFOpLambda)   (None, 32, 240)              0         ['up_sampling1d_1[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 32, 48)               57648     ['tf.concat_12[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_2 (UpSamplin  (None, 64, 48)               0         ['conv1d_13[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_13 (TFOpLambda)   (None, 64, 240)              0         ['up_sampling1d_2[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_18[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 64, 72)               86472     ['tf.concat_13[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_3 (UpSamplin  (None, 128, 72)              0         ['conv1d_14[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)   (None, 128, 240)             0         ['up_sampling1d_3[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_17[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 128, 96)              115296    ['tf.concat_14[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_4 (UpSamplin  (None, 256, 96)              0         ['conv1d_15[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)   (None, 256, 240)             0         ['up_sampling1d_4[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_16[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 256, 120)             144120    ['tf.concat_15[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_5 (UpSamplin  (None, 512, 120)             0         ['conv1d_16[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)   (None, 512, 240)             0         ['up_sampling1d_5[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_15[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 512, 144)             172944    ['tf.concat_16[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_6 (UpSamplin  (None, 1024, 144)            0         ['conv1d_17[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_17 (TFOpLambda)   (None, 1024, 240)            0         ['up_sampling1d_6[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_14[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 1024, 168)            201768    ['tf.concat_17[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_7 (UpSamplin  (None, 2048, 168)            0         ['conv1d_18[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_18 (TFOpLambda)   (None, 2048, 240)            0         ['up_sampling1d_7[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_13[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 2048, 192)            230592    ['tf.concat_18[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_8 (UpSamplin  (None, 4096, 192)            0         ['conv1d_19[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_19 (TFOpLambda)   (None, 4096, 240)            0         ['up_sampling1d_8[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_12[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 4096, 216)            259416    ['tf.concat_19[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_9 (UpSamplin  (None, 8192, 216)            0         ['conv1d_20[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat_20 (TFOpLambda)   (None, 8192, 240)            0         ['up_sampling1d_9[0][0]',     \n",
      "                                                                     'tf.__operators__.getitem_11[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 8192, 240)            288240    ['tf.concat_20[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling1d_10 (UpSampli  (None, 16384, 240)           0         ['conv1d_21[0][0]']           \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " tf.concat_21 (TFOpLambda)   (None, 16384, 264)           0         ['up_sampling1d_10[0][0]',    \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 16384, 264)           348744    ['tf.concat_21[0][0]']        \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (3,)                         0         ['input[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (3,)                         0         ['conv1d_22[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLamb  (3,)                         0         ['tf.compat.v1.shape_1[0][0]',\n",
      " da)                                                                 'tf.compat.v1.shape[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div (TF  (3,)                         0         ['tf.math.subtract[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.floor_div[0][0]\n",
      " 3 (SlicingOpLambda)                                                ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
      " 4 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 16384, 1)             265       ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.floor_div[0][0]\n",
      " 2 (SlicingOpLambda)                                                ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  ()                           0         ['tf.__operators__.getitem_23[\n",
      " Lambda)                                                            0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_24[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, None, 1)              0         ['input[0][0]',               \n",
      " 5 (SlicingOpLambda)                                                 'tf.__operators__.getitem_22[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 16384, 1)             0         ['conv1d_23[0][0]']           \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_3 (TFOp  (3,)                         0         ['tf.__operators__.getitem_25[\n",
      " Lambda)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOp  (3,)                         0         ['tf.__operators__.add_1[0][0]\n",
      " Lambda)                                                            ']                            \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLa  (3,)                         0         ['tf.compat.v1.shape_3[0][0]',\n",
      " mbda)                                                               'tf.compat.v1.shape_2[0][0]']\n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_1 (  (3,)                         0         ['tf.math.subtract_1[0][0]']  \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.floor_div_1[0][\n",
      " 7 (SlicingOpLambda)                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_2[0][0]']\n",
      " 8 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.floor_div_1[0][\n",
      " 6 (SlicingOpLambda)                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  ()                           0         ['tf.__operators__.getitem_27[\n",
      " OpLambda)                                                          0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_28[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, None, 1)              0         ['tf.__operators__.getitem_25[\n",
      " 9 (SlicingOpLambda)                                                0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_26[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLa  (None, 16384, 1)             0         ['tf.__operators__.getitem_29[\n",
      " mbda)                                                              0][0]',                       \n",
      "                                                                     'tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5778217 (22.04 MB)\n",
      "Trainable params: 5778217 (22.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model():\n",
    "    # Input\n",
    "    input_mix = Input(shape=(num_frames, num_channels), name=\"input\")\n",
    "\n",
    "    # Encoder\n",
    "    enc_outputs = create_encoder(input_mix, num_layers, num_initial_filters, filter_size, input_filter_size, padding)\n",
    "\n",
    "    # Decoder\n",
    "    current_layer = create_decoder(enc_outputs, num_layers, num_initial_filters, filter_size, merge_filter_size, padding, upsampling)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = get_output_layer(current_layer, input_mix, output_type, source_names, num_channels, output_filter_size, padding, activation, training)\n",
    "\n",
    "\n",
    "    # Build Model\n",
    "    model = Model(inputs=input_mix, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Building the model\n",
    "model = build_model()\n",
    "\n",
    "# Compile the model (if needed)\n",
    "model.compile(optimizer='adam', loss='mse') # or other appropriate loss and optimizer\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "models_folder = \"/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/\"\n",
    "save_path = '/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/Models/best_model.h5'\n",
    "\n",
    "# load M1\n",
    "model_m1 = load_model(save_path, custom_objects={'r_squared': r_squared})\n",
    "\n",
    "output_type = 'difference'  # Change output type to 'difference'\n",
    "model_m2 = build_model()\n",
    "\n",
    "for layer_m1, layer_m2 in zip(model_m1.layers[:-len(source_names)], model_m2.layers[:-len(source_names)]):\n",
    "    layer_m2.set_weights(layer_m1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.13e-6\n",
    "BATCH_SIZE = 16*2\n",
    "EPOCHS = 2000\n",
    "num_frames = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "SNIPPET_LENGTH = num_frames\n",
    "tfRecord_Datasets = '/Users/rei/Documents/Machine_Learning/MODELS/Unet/Unet_Sound_Seperation/Unet-Sound-Seperation/tf_Record'\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'mixed_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32),\n",
    "        'vocal_signal': tf.io.FixedLenFeature([SNIPPET_LENGTH], tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    return example['mixed_signal'], example['vocal_signal']\n",
    "\n",
    "def load_dataset(filename):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    return raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Load your training, validation and test data\n",
    "train_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'train_2.tfrecord'))\n",
    "val_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'val_2.tfrecord'))\n",
    "test_dataset = load_dataset(os.path.join(tfRecord_Datasets, 'test_2.tfrecord'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cmxxfbqp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cmxxfbqp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project='Large_Shaking_Through_Unet_model', name='CPU-Batch16-lr1.13e-5-M2')\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Set up early stopping based on validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Assuming train_dataset and val_dataset are your training and validation data generators or datasets\n",
    "# You might need to adjust this part based on how you've set up your data\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE),\n",
    "                    validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=[early_stopping, wandb.keras.WandbCallback()])\n",
    "\n",
    "# Fine-tuning phase\n",
    "#model.compile(optimizer=Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999), loss='mean_squared_error')\n",
    "#history_fine_tune = model.fit(train_dataset, validation_data=val_dataset, epochs=2000, batch_size=32, callbacks=[early_stopping, wandb.keras.WandbCallback()])\n",
    "\n",
    "# You might want to save the model after training\n",
    "model.save(models_folder + 'best_model.h5-M2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
